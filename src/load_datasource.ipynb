{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee353e42-ff58-4955-9608-12865bd0950e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Install Notebook\n",
    "\n",
    "This notebook is used to create the custom pbf datasource. It will also install the required dependencies.\n",
    "\n",
    "IMPORTANT: The initial PBF reading occurs on a single machine using libosmium.\n",
    "Performance Tips:\n",
    "- Use a machinetype with sufficient memory and CPU\n",
    "- Apply filters for optimal performance:\n",
    "  1. emptyTagFilter: Removes entries with no tags\n",
    "  2. keyFilter: Filters for specific OSM keys\n",
    "  3. tagFilter: Filters for specific key-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bca260b-13d1-448f-8082-30b60a85c9ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet osmium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import osmium\n",
    "import ast\n",
    "from pyspark.sql.datasource import DataSource, DataSourceReader\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, MapType\n",
    "from typing import Generator, Optional, Tuple, Dict\n",
    "\n",
    "class PBFToGeometryDataSourceReader(DataSourceReader):\n",
    "    \"\"\"\n",
    "    Data source reader to read OSM PBF files and convert them to geometries.\n",
    "\n",
    "    This class processes OSM PBF files to extract geometries (e.g., points, lines, or polygons)\n",
    "    and associated metadata (tags). The output can be configured to include geometries in\n",
    "    Well-Known Text (WKT), Well-Known Binary (WKB), or GeoJSON formats.\n",
    "\n",
    "    Attributes:\n",
    "        schema (StructType): The schema of the output data, including fields for ID, type, geometry, and tags.\n",
    "        options (dict): Configuration options to customize the data reader.\n",
    "\n",
    "    Options:\n",
    "        - `path` (str): The file path to the input PBF file. **Required**.\n",
    "        - `geometryType` (str): The output geometry format. Supported values:\n",
    "          - `\"WKT\"`: Well-Known Text (default).\n",
    "          - `\"WKB\"`: Well-Known Binary.\n",
    "          - `\"GeoJSON\"`: GeoJSON format.\n",
    "        - `emptyTagFilter` (bool): Whether to exclude OSM elements with no tags. Default: `True`.\n",
    "        - `keyFilter` (str): A key-based filter for OSM tags. Only elements with this key will be processed. Example: `\"highway\"`.\n",
    "        - `tagFilter` (str): A filter based on specific key-value tag pairs. Should be a tuple-like string, e.g., `\"('amenity', 'cafe')\"`.\n",
    "          Only elements with this key-value pair will be processed.\n",
    "\n",
    "    Example Usage:\n",
    "        df = (\n",
    "            spark.read.format(\"pbf\")\n",
    "            .option(\"path\", path)\n",
    "            .option(\"geometryType\", \"WKT\")\n",
    "            .option(\"emptyTagFilter\", True)\n",
    "            .option(\"keyFilter\", \"building\")\n",
    "            .option(\"tagFilter\", \"('building', 'hospital')\")\n",
    "            .load()\n",
    "        )\n",
    "    \"\"\"\n",
    "    def __init__(self, schema: StructType, options: dict):\n",
    "        \"\"\"\n",
    "        Initialize the PBFToGeometryDataSourceReader.\n",
    "\n",
    "        Args:\n",
    "            schema (StructType): The schema of the output data.\n",
    "            options (dict): Options to configure the data reader, such as file path and filters.\n",
    "        \"\"\"\n",
    "        self.schema: StructType = schema\n",
    "        self.options: dict = options\n",
    "\n",
    "    def read(self, partition: Optional[int] = None) -> Generator[Tuple[int, str, Optional[str], Dict[str, str]], None, None]:\n",
    "        \"\"\"\n",
    "        Read the PBF file and yield geometry data for each OSM element.\n",
    "\n",
    "        Args:\n",
    "            partition (Optional[int]): Partition index, if applicable. Not implemented.\n",
    "\n",
    "        Yields:\n",
    "            tuple: A tuple containing the element ID, type, geometry, and tags.\n",
    "        \"\"\"\n",
    "        # Extract options\n",
    "        input_path: str = self.options.get(\"path\")\n",
    "        if not input_path:\n",
    "            raise ValueError(\"The 'path' option is required.\")\n",
    "\n",
    "        geometry_type: str = self.options.get(\"geometryType\", \"WKT\").upper()\n",
    "        if geometry_type not in [\"WKT\", \"WKB\", \"GEOJSON\"]:\n",
    "            raise ValueError(\"Invalid geometryType option. Choose 'WKT', 'WKB', or 'GeoJSON'.\")\n",
    "\n",
    "        # Ensure the file exists\n",
    "        input_file: Path = Path(input_path)\n",
    "        if not input_file.exists():\n",
    "            raise FileNotFoundError(f\"Input file {input_path} not found.\")\n",
    "\n",
    "        # Choose the appropriate geometry factory\n",
    "        if geometry_type == \"WKT\":\n",
    "            geometry_factory = osmium.geom.WKTFactory()\n",
    "        elif geometry_type == \"WKB\":\n",
    "            geometry_factory = osmium.geom.WKBFactory()\n",
    "        elif geometry_type == \"GEOJSON\":\n",
    "            geometry_factory = osmium.geom.GeoJSONFactory()\n",
    "\n",
    "        # Extract filters and parse them properly\n",
    "        apply_empty_tag_filter: bool = self.options.get(\"emptyTagFilter\", \"True\").lower() == \"true\"\n",
    "\n",
    "        # Parse keyFilter option, default to None if not provided\n",
    "        key_filter: Optional[str] = self.options.get(\"keyFilter\", None)\n",
    "\n",
    "        # Parse tagFilter option from a flat string to a list of tuples\n",
    "        tag_filter_str: Optional[str] = self.options.get(\"tagFilter\", None)\n",
    "        tag_filter: Optional[Tuple[str, str]] = None\n",
    "        if tag_filter_str:\n",
    "            try:\n",
    "                tag_filter = ast.literal_eval(tag_filter_str)\n",
    "                if not isinstance(tag_filter, tuple) or len(tag_filter) != 2:\n",
    "                    raise ValueError(\"tagFilter must be a tuple-like string (e.g., \\\"('key', 'value')\\\").\")\n",
    "            except (ValueError, SyntaxError) as e:\n",
    "                raise ValueError(f\"Invalid tagFilter format: {tag_filter_str}. Error: {e}\")\n",
    "\n",
    "        # Setup processor with filters\n",
    "        processor = osmium.FileProcessor(input_path)\n",
    "        if apply_empty_tag_filter:\n",
    "            processor = processor.with_filter(osmium.filter.EmptyTagFilter())\n",
    "        if key_filter:\n",
    "            processor = processor.with_filter(osmium.filter.KeyFilter(key_filter))\n",
    "        if tag_filter:\n",
    "            processor = processor.with_filter(osmium.filter.TagFilter(tag_filter))\n",
    "\n",
    "        # Yield the geometry data\n",
    "        for element in processor.with_areas():\n",
    "            geometry: Optional[str] = None\n",
    "            tags: Dict[str, str] = {}\n",
    "            try:\n",
    "                # Generate geometry based on the type of element\n",
    "                if element.is_node():\n",
    "                    geometry = geometry_factory.create_point(element.location)\n",
    "                elif element.is_way() and not element.is_closed():\n",
    "                    geometry = geometry_factory.create_linestring(element.nodes)\n",
    "                elif element.is_area():\n",
    "                    geometry = geometry_factory.create_multipolygon(element)\n",
    "\n",
    "                # Extract tags for the element\n",
    "                tags = {tag.k: tag.v for tag in element.tags}\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing element {element.id}: {e}\")\n",
    "                continue\n",
    "\n",
    "            yield (element.id, element.type_str(), geometry, tags)\n",
    "\n",
    "class PBFToGeometryDataSource(DataSource):\n",
    "    \"\"\"\n",
    "    A custom data source to convert OSM PBF files to geometries in WKT, WKB, or GeoJSON format,\n",
    "    including tags for each object, using MapType for tags.\n",
    "    \"\"\"\n",
    "    @classmethod\n",
    "    def name(cls) -> str:\n",
    "        \"\"\"\n",
    "        Get the name of the data source.\n",
    "\n",
    "        Returns:\n",
    "            str: The name of the data source.\n",
    "        \"\"\"\n",
    "        return \"pbf\"\n",
    "\n",
    "    def schema(self) -> StructType:\n",
    "        \"\"\"\n",
    "        Define the schema for the output data.\n",
    "\n",
    "        Returns:\n",
    "            StructType: The schema including fields for ID, type, geometry, and tags.\n",
    "        \"\"\"\n",
    "        return StructType([\n",
    "            StructField(\"id\", LongType(), True),\n",
    "            StructField(\"type\", StringType(), True),\n",
    "            StructField(\"geometry\", StringType(), True),\n",
    "            StructField(\"tags\", MapType(StringType(), StringType()), True)\n",
    "        ])\n",
    "\n",
    "    def reader(self, schema: StructType) -> PBFToGeometryDataSourceReader:\n",
    "        \"\"\"\n",
    "        Create a data source reader for reading the PBF file.\n",
    "\n",
    "        Args:\n",
    "            schema (StructType): The schema of the output data.\n",
    "\n",
    "        Returns:\n",
    "            PBFToGeometryDataSourceReader: An instance of the data source reader.\n",
    "        \"\"\"\n",
    "        return PBFToGeometryDataSourceReader(schema, self.options)\n",
    "\n",
    "# Register the custom data source\n",
    "spark.dataSource.register(PBFToGeometryDataSource)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
